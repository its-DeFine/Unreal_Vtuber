version: "3.9"

services:
  # Override existing NeuroSync service to launch BOTH core API & BYOC worker
  neurosync:
    image: ghcr.io/its-define/neurobridge:main
    container_name: neurosync_byoc
    mem_limit: 12g # Add memory limit
    environment:
      # --- BYOC worker ---
      - ORCH_URL=https://orchestrator:9995
      - ORCH_SECRET=orch-secret            # must match orchestrator flag -orchSecret
      - CAPABILITY_NAME=start-echo-test    # matches server_adapter default
      - CAPABILITY_DESCRIPTION=NeuroSync bridge demo
      - CAPABILITY_URL=http://neurosync:9876
      - CAPABILITY_CAPACITY=1
      - CAPABILITY_PRICE_PER_UNIT=1000
      - CAPABILITY_PRICE_SCALING=1
      - SERVER_PORT=9876                   # port the worker binds
      # --- NeuroSync Local API ---
      - FLASK_HOST=0.0.0.0
      # Ensure PulseAudio environment variables are set
      - PULSE_SERVER="tcp:host.docker.internal:4713"
      - PULSE_COOKIE=""          # cookie not needed for tcp on Windows/WSL
      - USE_CUDA=false # Keeping this as per user's instruction
      - NEUROSYNC_BLENDSHAPES_URL=http://neurosync:5000/audio_to_blendshapes
      - AUDIO_PLAYBACK_DEVICE=auto
      # TTS Configuration - Kokoro TTS Integration
      - TTS_PROVIDER=kokoro
      - KOKORO_TTS_SERVER_URL=http://host.docker.internal:6006
      - KOKORO_DEFAULT_VOICE=af_sarah
      - KOKORO_TTS_TIMEOUT=30
      - KOKORO_TTS_LANGUAGE=en
      # LLM Configuration - Connect to Ollama if running
      - LLM_PROVIDER=ollama
      - OLLAMA_API_ENDPOINT=http://ollama:11434
      - OLLAMA_MODEL=llama3.2:3b
      - OLLAMA_STREAMING=true
    networks:
      - scb_bridge_net  # original network for Eliza bridge
      - byoc            # new network for orchestrator/gateway
    deploy: # Add deploy configuration for GPU access
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1 # or 'all'
              capabilities: [gpu]
    depends_on:
      - orchestrator
      - gateway
      - redis
    env_file:
      - ../.env
    volumes:
      # - ${XDG_RUNTIME_DIR}/pulse:/run/user/1000/pulse      # socket + cookie. Commented out to prefer TCP.
      - /etc/machine-id:/etc/machine-id:ro                 # libpulse wants this
    # devices: # Commented out as /dev/snd might not be available in WSL2
    group_add:
      - "29"   # 29 == audio on Debian/Ubuntu; adjust if different
    ports:
      - "5000:5000"    # Local API
      - "9876:9876"    # BYOC worker (handy for curl)

  # === Orchestrator ===
  orchestrator:
    image: adastravideo/go-livepeer:dynamic-capabilities-2
    container_name: byoc-orchestrator
    volumes:
      - ../data/orchestrator:/data
    ports:
      - 9995:9995
    env_file:
      - ../.env
    command: ["-orchestrator",
          "-orchSecret=${ORCH_SECRET}",
          "-serviceAddr=0.0.0.0:9995",
          "-v=6",
          "-network=arbitrum-one-mainnet",
          "-ethUrl=https://arb1.arbitrum.io/rpc",
          "-ethPassword=${ETH_PASSWORD}",
          "-dataDir=/data",
          "-ethOrchAddr=",
          "-pricePerUnit=1"]
    networks:
      - byoc

  # === Gateway (optional for on-chain) ===
  gateway:
    image: adastravideo/go-livepeer:dynamic-capabilities-2
    container_name: byoc-gateway
    command: ["-gateway", "-orchAddr=https://orchestrator:9995", "-httpAddr=0.0.0.0:9999", "-network=offchain"]
    ports:
      - "9999:9999"
    volumes:
      - ../data/gateway:/data
    networks:
      - byoc

  # === Caddy ===
  caddy:
    image: ghcr.io/its-define/webapp:main
    container_name: byoc-webapp
    ports:
      - "8088:8088"
    networks:
      - byoc
    restart: unless-stopped

  # Ollama Local LLM Server (GPU-enabled by default)
  ollama:
    image: ollama/ollama:latest
    container_name: vtuber-ollama
    ports:
      - "11434:11434"
    volumes:
      - ../ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_KEEP_ALIVE=24h
    restart: unless-stopped
    networks:
      - scb_bridge_net
      - byoc
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Make this optional so the main system can run without it
    profiles:
      - ollama

networks:
  byoc:
    driver: bridge 