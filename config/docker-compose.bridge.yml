# Docker Compose for running NeuroSync (S1) and Eliza/the-org (S2)
# in a shared network for local development and testing the SCB bridge.
#
# Usage: docker compose -f docker-compose.yml -f docker-compose.bridge.yml up --build

services:
  eliza_the_org:
    build:
      context: ../eliza-livepeer-integration
      dockerfile: Dockerfile
    container_name: eliza_the_org_s2
    working_dir: /app/packages/the-org
    env_file:
      - ../.env
    command: >
      bash -c "set -x; \
      echo '>>> [Eliza] Starting dev server with auto-selection of pglite...'; \
      cd /app/packages/the-org && echo -e '\n' | bun run dev"
    ports:
      - "3000:3000" # Expose port 3000 (host:container)
    environment:
      - NEUROSYNC_URL=http://neurosync:5000    # point at API container
      - SCB_TOKENS=600
      - LOG_LEVEL=debug # Enable debug logs for testing
      # Add other Eliza/the-org env vars as needed (e.g., Discord tokens)
      # Ensure the correct agent(s) are enabled via env or config
      - DATABASE_ADAPTER="pglite"
      - PGLITE_PROMPT=false # Skip the database selection prompt
    networks:
      - scb_bridge_net
    depends_on:
      - neurosync
      - redis
  neurosync:
    mem_limit: 12g
    build:
      context: ..
      dockerfile: ./NeuroBridge/dockerfile  # Builds combined Local API + Player image
    container_name: neurosync_s1
    command: [/app/entrypoint_bridge.sh]
    ports:
      - "5000:5000" # Expose Flask API port
      - "5001:5001" # Expose Player HTTP Server port
    environment:
      - FLASK_HOST=0.0.0.0
      - PYTHONUNBUFFERED=1
      - ALLOWED_ORIGINS=*
      - PLAYER_PORT=5001 # Set Player HTTP Server port
      # SCB storage
      - USE_REDIS_SCB=true
      - REDIS_URL=redis://redis:6379/0
      # - LIVELINK_UDP_IP=your_host_ip_address_here # Commented out to use default 'host.docker.internal'
      # Add other NeuroSync env vars as needed (e.g., USE_REDIS_SCB)
    deploy: # Add deploy configuration for GPU access
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1 # or 'all'
              capabilities: [gpu]
    networks:
      - scb_bridge_net
    volumes:
      # Mount NeuroBridge code for live editing (optional)
      - ../NeuroBridge:/app/NeuroBridge
    env_file:
      - ../.env
    # Default CMD in image already starts Flask + client
    # Add healthcheck if desired
    # healthcheck:
    #   test: ["CMD", "curl", "--fail", "http://localhost:5000/scb/ping"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 3
  redis:
    image: redis:7-alpine
    container_name: redis_scb
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - scb_bridge_net
    restart: unless-stopped

  # PostgreSQL database for autonomous agent
  postgres:
    image: ankane/pgvector:latest
    container_name: autonomous_postgres_bridge
    environment:
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_DB=autonomous_agent
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - autonomous_postgres_data:/var/lib/postgresql/data:rw
    ports:
      - '127.0.0.1:5434:5432'  # Different port to avoid conflicts with other postgres instances
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}']
      interval: 5s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - scb_bridge_net
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Database initialization service - runs analytics setup automatically
  db_init:
    image: postgres:16-alpine
    container_name: autonomous_db_init
    environment:
      - PGPASSWORD=postgres
    volumes:
      - ../tools/database/setup_analytics_tables.sql:/setup_analytics_tables.sql:ro
    networks:
      - scb_bridge_net
    depends_on:
      postgres:
        condition: service_healthy
    command: >
      sh -c "
      echo 'üîß [DB_INIT] Starting database initialization...';
      echo 'üìä [DB_INIT] Setting up analytics tables for autonomous agent...';
      psql -h postgres -U postgres -d autonomous_agent -f /setup_analytics_tables.sql;
      if [ $$? -eq 0 ]; then
        echo '‚úÖ [DB_INIT] Database analytics setup completed successfully!';
      else
        echo '‚ùå [DB_INIT] Database setup failed!';
        exit 1;
      fi;
      echo 'üéØ [DB_INIT] Autonomous agent database is ready for Phase 2!';
      "
    restart: "no"  # Only run once
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# --- RTMP server for low-latency audio/video sync ---
# Old block commented out due to indentation fix
#nginx-rtmp:
#  build: ./files_docker_rtmp/docker/rtmp
#  container_name: nginx_rtmp
#  ports:
#    - "1935:1935"   # RTMP ingest
#    - "8080:8080"   # HLS + status page
#  volumes:
#    - ./files_docker_rtmp/docker/rtmp/nginx.conf:/etc/nginx/nginx.conf
#  networks:
#    - scb_bridge_net
#  restart: unless-stopped
# --- RTMP server for low-latency audio/video sync ---
  nginx-rtmp:
    build:
      context: ../files_docker_rtmp/docker/rtmp
    container_name: nginx_rtmp
    ports:
      - "1935:1935"   # RTMP ingest
      - "8080:8080"   # HLS + status page & HLS manifest
    volumes:
      - ../files_docker_rtmp/docker/rtmp/nginx.conf:/etc/nginx/nginx.conf:ro
    networks:
      - scb_bridge_net
    restart: unless-stopped

  autonomous_starter:
    build:
      context: ../autonomous-starter          # directory with its Dockerfile
      dockerfile: Dockerfile                 # or omit if named "Dockerfile"
    container_name: autonomous_starter_s3
    working_dir: /app                        # adjust if your code lives elsewhere
    env_file:
      - ../.env
    ports:
      # inside the container it still binds to 3000,
      # but we publish it on 3100 so it doesn't fight with eliza_the_org
      - "3100:3000"
    environment:
      - PORT=3000                            # what the app listens on
      - LOG_LEVEL=debug
      # AI Provider Configuration - Testing Livepeer as primary
      - MODEL_PROVIDER=livepeer              # Set Livepeer as primary provider
      - LIVEPEER_GATEWAY_URL=https://dream-gateway.livepeer.cloud
      - LIVEPEER_API_KEY=                    # No API key needed for testing
      - LIVEPEER_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
      - LIVEPEER_LARGE_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
      - LIVEPEER_SMALL_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
      - LIVEPEER_TEMPERATURE=0.6
      - LIVEPEER_MAX_TOKENS=2048
      # Disable other providers to force Livepeer usage
      - OPENAI_API_KEY=                      # Disable OpenAI
      - ANTHROPIC_API_KEY=                   # Disable Anthropic  
      - GROQ_API_KEY=                        # Disable Groq
      # VTuber and System Configuration
      - VTUBER_ENDPOINT_URL=http://neurosync:5001/process_text
      - NEUROSYNC_URL=http://neurosync:5000   # in case any other actions need it
      - NEUROSYNC_SCB_URL=http://neurosync:5000/scb/update
      - AUTONOMOUS_LOOP_INTERVAL=30000        # 30 seconds between iterations
      # Database Configuration - Connect to the postgres service in this network
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/autonomous_agent
      - POSTGRES_URL=postgresql://postgres:postgres@postgres:5432/autonomous_agent
      - DB_TYPE=postgres
    networks:
      - scb_bridge_net
    depends_on:
      postgres:
        condition: service_healthy
      neurosync:
        condition: service_started
      db_init:
        condition: service_completed_successfully
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  scb_bridge_net:
    driver: bridge

volumes:
  redis_data:
    driver: local
  autonomous_postgres_data:
    driver: local
    name: autonomous_postgres_bridge_data