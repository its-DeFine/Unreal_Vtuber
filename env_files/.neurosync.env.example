# LLM Configuration
# Options: "openai", "llama3_1", "llama3_2"
LLM_PROVIDER=openai
OPENAI_API_KEY= # YOUR_OPENAI_API_KEY_HERE e.g. sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-3.5-turbo # Or your preferred OpenAI model

# Local Llama endpoints
LLAMA_3_1_ENDPOINT=http://127.0.0.1:5050/generate_llama
LLAMA_3_1_STREAM_ENDPOINT=http://127.0.0.1:5050/generate_stream
LLAMA_3_2_ENDPOINT=http://127.0.0.1:5050/generate_llama
LLAMA_3_2_STREAM_ENDPOINT=http://127.0.0.1:5050/generate_stream

# TTS Configuration
# Options: "elevenlabs", "local", "neurosync"
TTS_PROVIDER=elevenlabs
ELEVENLABS_API_KEY= # YOUR_ELEVENLABS_API_KEY_HERE e.g. sk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
ELEVENLABS_VOICE_ID= # YOUR_ELEVENLABS_VOICE_ID_HERE e.g. JBFqnCBsd6RMkjVDRZzb
ELEVENLABS_MODEL_ID=eleven_multilingual_v2 # Or your preferred ElevenLabs model

# Local TTS Configuration
LOCAL_TTS_URL=http://127.0.0.1:5000/tts
LOCAL_TTS_VOICE=default

# Neurosync TTS Configuration (if TTS_PROVIDER=neurosync)
NEUROSYNC_TTS_URL=http://127.0.0.1:5000/text_to_blendshapes
NEUROSYNC_BLENDSHAPES_URL=http://127.0.0.1:5000/audio_to_blendshapes 
NEUROSYNC_TTS_VOICE=default

# General LLM Configuration (primarily for local models if not overridden by provider-specific settings)
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3
LLM_MAX_LENGTH=2048
LLM_TEMPERATURE=0.5
LLM_TOP_P=0.9
LLM_REPETITION_PENALTY=1.0

# Authentication (e.g., for Hugging Face models)
HF_TOKEN= # YOUR_HUGGINGFACE_TOKEN_HERE (if needed for private/gated models)

# Quantization Settings (for local models)
QUANTIZATION=fp8 # Options: fp16, bf16, fp8, int8, int4, nf4 (check model compatibility)
BNB_4BIT_QUANT_TYPE=fp8 # Options for bitsandbytes 4-bit quantization: fp4, nf4
BNB_4BIT_USE_DOUBLE_QUANT=false
BNB_4BIT_COMPUTE_DTYPE=bfloat16 # Options: float16, bfloat16, float32

# TTS Configuration (primarily for local/Hugging Face TTS if not overridden by provider-specific settings)
TTS_MODEL=facebook/mms-tts-eng  # HuggingFace-compatible TTS model
TTS_SPEED=1.0  # 1.0 is normal speed, lower for slower, higher for faster
TTS_SPEAKER_WAV=voices/default.wav  # Path to reference voice sample for cloning (if supported by local TTS)
TTS_LANGUAGE=en  # Language code (en, fr, de, es, etc.)
TTS_STREAM_CHUNK_SIZE=50  # Increased from 20 to process more frames in each streaming chunk

# Pipeline Configuration
CHUNK_WORD_THRESHOLD=8  # Increased from 3 to get more natural speech chunks
SHOW_REALTIME_METRICS=true  # Whether to show metrics in real-time (true/false)
SAVE_AUDIO=true  # Whether to save the generated audio (true/false)
AUDIO_OUTPUT_PATH=combined_output.wav # Default path for saved audio
# SCB_API_DEBUG=true # This seems to be more related to Eliza, but was in the original NeuroSync part

# Performance Optimization
USE_CUDA=true  # auto, true, or false - set to true for adequate VRAM (e.g., 16GB+ for some models)
OPTIMIZE_MEMORY=true  # Use memory optimization techniques (true/false)
TRUST_REMOTE_CODE=true  # Required for some Hugging Face models like Mistral (true/false)
LOW_CPU_MEM_USAGE=true  # Helps with memory management (true/false)

# Cognitive update (Specific to NeuroSync internal bridging, keep as is or consult NeuroSync docs)
ENABLE_SYSTEM2_BRIDGE=true
MOCK_SYSTEM2=true
BRIDGE_DEBUG=true

# USE_REDIS_SCB=true # This also seems more related to Eliza, but was in the original NeuroSync part 